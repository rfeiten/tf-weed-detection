{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github//pylabel-project/samples/blob/main/pylabel2azure_custom_vision.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> \n",
    "# Upload Annotations to Azure Custom Vision \n",
    "Custom Vision, part of the Azure Cognitive Services family, is a solution for training and deploying custom computer vision models. Custom Vision includes an API to upload images and annotations to train a custom model. Using PyLabel you can import existing labels in COCO, YOLOv5, or VOC format and then upload the dataset to Custom Vision.  \n",
    "\n",
    "This notebook demonstrates how to import a custom dataset in YOLO format to Custom Vision. To complete the steps you will need an Azure Account and a Custom Vision subscription. Follow [this tutorial on the the Custom Vision site](https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/quickstarts/object-detection?tabs=visual-studio&pivots=programming-language-python) to setup your account and make sure it is working before using this notebook to import a custom dataset. When you are ready to use this notebook to upload a custom dataset, it is recommended to open https://www.customvision.ai/ so you can see the results of the commands you are performing through the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-cognitiveservices-vision-customvision\n",
    "%pip install pylabel\n",
    "\n",
    "#Import Azure cognitive services libraries \n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n",
    "#Import other libraries used in this notebook \n",
    "import os, zipfile\n",
    "from pathlib import PurePath\n",
    "from os.path import exists\n",
    "from decimal import *\n",
    "\n",
    "from pylabel import importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your Azure endpoint and subscription keys.\n",
    "ENDPOINT = \"\"\n",
    "training_key = \"\"\n",
    "prediction_key = \"\"\n",
    "prediction_resource_id = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize objects used by Azure Congitive vision\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain in trainer.get_domains():\n",
    "    # Print the domain name\n",
    "    print(domain.name + \" - \" + domain.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new project\n",
    "#Change the domain name accordingly\n",
    "publish_iteration_name = \"detectModel\"\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General (compact) [S1]\")\n",
    "project = trainer.create_project(\"Imported Weed Detection\", domain_id=obj_detection_domain.id)\n",
    "#If you browse to https://www.customvision.ai/ you should see a new project called \"PyLabel Sample Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Custom Dataset \n",
    "For this demonstration we will download 100 images from the <a href=\"https://github.com/pylabel-project/datasets_models#squirrels-and-nuts\">squirrels and nuts dataset with annotations in YOLOv5 format.</a> PyLabel can also import datasets in COCO and PASCAL VOC format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "os.makedirs(\"data/\", exist_ok=True)\n",
    "!wget \"https://github.com/pylabel-project/datasets_models/blob/main/squirrelsandnuts/squirrelsandnuts_train.zip?raw=true\" -O data/squirrelsandnuts_train.zip\n",
    "with zipfile.ZipFile(\"data/squirrelsandnuts_train.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import annotations as a PyLabel dataset\n",
    "dataset = importer.ImportYoloV5(path=\"C:/Users/myuser/train/labels\",\n",
    "        path_to_images=\"C:/Users/myuser/train/images\", \n",
    "        img_ext=\"jpg\",\n",
    "        cat_names=['Lolium_Multiflorum','Conyza_Bonariensis', 'Digitaria_Insularis', 'Eleusine_Indica', 'Amaranthus_Palmeri']\n",
    "    )\n",
    "dataset.df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import to Azure Custom Vision\n",
    "PyLabel stores the annotations as a pandas dataframe. Now you can use extract the annotations from the dataframe and use it as inputs to the Custom Vision APIs. \n",
    "\n",
    "The first step is to create tags for each of the classes in your custom dataset. A list of class names is available in the dataset.analyze.classes property. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.analyze.classes)\n",
    "#Create a tag for each class and store then in a dict where the class name is the key\n",
    "tags = {}\n",
    "for class_name in dataset.analyze.classes:\n",
    "    tag = trainer.create_tag(project.id, class_name)\n",
    "    tags[class_name] = tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you check your account on https://www.customvision.ai/ you should see a new project called \"PyLabel Sample Dataset\" with 2 tags added: Squirrels and Nuts. \n",
    "\n",
    "You are ready to upload your images and annotations. For each image in your dataset you will need to add \"Regions\" for each bounding box and then upload the image and annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate the rows for each image in the dataframe\n",
    "for img_filename, img_df in dataset.df.groupby('img_filename'):\n",
    "    img_path = str(PurePath(dataset.path_to_annotations, str(img_df.iloc[0].img_folder), img_filename))\n",
    "    assert exists(img_path), f\"File does not exist: {img_path}\"\n",
    "\n",
    "    #Create a region object for each bounding box in the dataset \n",
    "    regions = []\n",
    "    for index, row in img_df.iterrows():\n",
    "\n",
    "        #Normalize the boundings box coordinates between 0 and 1\n",
    "        x = Decimal(row.ann_bbox_xmin / row.img_width).min(1)\n",
    "        y = Decimal(row.ann_bbox_ymin / row.img_height).min(1)\n",
    "        w = Decimal(row.ann_bbox_width / row.img_width).min(1-x)\n",
    "        h = Decimal(row.ann_bbox_height / row.img_height).min(1-y)\n",
    "        \n",
    "        regions.append(Region(\n",
    "                tag_id=tags[row.cat_name].id, \n",
    "                left=x,\n",
    "                top=y,\n",
    "                width=w,\n",
    "                height=h\n",
    "            )\n",
    "        )\n",
    "\n",
    "    #Create an object with the image and all of the annotations for that image\n",
    "    with open(img_path, mode=\"rb\") as image_contents:\n",
    "        image_and_annotations = [ImageFileCreateEntry(name=img_filename, contents=image_contents.read(), regions=regions)]\n",
    "\n",
    "    #Upload the image and all annnotations for that image\n",
    "    upload_result = trainer.create_images_from_files(\n",
    "            project.id, \n",
    "            ImageFileCreateBatch(images=image_and_annotations)\n",
    "        )\n",
    "    \n",
    "    #If upload is not successful, print details about that image for debugging \n",
    "    if not upload_result.is_batch_successful:\n",
    "        print(\"Image upload failed.\")\n",
    "        for image in upload_result.images:\n",
    "            print(img_path)\n",
    "            print(\"Image status: \", image.status)\n",
    "            print(regions)\n",
    "\n",
    "#This will take a few minutes \n",
    "print(\"Upload complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should see all of your images uploaded to https://www.customvision.ai/.\n",
    "<p>\n",
    "<img src=\"https://raw.githubusercontent.com/pylabel-project/datasets_models/main/pylabel_assets/custom_vision_project.png\" width=400>\n",
    "<p>\n",
    "Click and image to see the bounding boxes.\n",
    "<p>\n",
    "<img src=\"https://raw.githubusercontent.com/pylabel-project/datasets_models/main/pylabel_assets/custom_vision_image.png\" width=400>\n",
    "<p>\n",
    "\n",
    "Now you are ready to train a model, which you can do at https://www.customvision.ai/. \n",
    "- If find a problem with this notebook, please report it as an issue here: https://github.com/pylabel-project/pylabel/issues \n",
    "- If have other questions, please start a discussion here: https://github.com/pylabel-project/pylabel/discussions. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "224f10583582cbeb83347e66d7d5874fb4e3ef8613e486088287d7c0b66e9aac"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
